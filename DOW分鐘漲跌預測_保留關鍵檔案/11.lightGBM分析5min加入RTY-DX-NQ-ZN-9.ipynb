{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Duplicate key in file WindowsPath('d:/source/Anaconda/lib/site-packages/matplotlib/mpl-data/matplotlibrc'), line 258 ('font.family:  Microsoft JhengHei')\n"
     ]
    }
   ],
   "source": [
    "import lightgbm as lgb\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error,r2_score\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from typing import List, Dict, Tuple\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
    "import warnings\n",
    "import cupy as cp\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"datas/5min_MYM_量價+YM+ES+VIX+ZN+RTY+NQ+DX資料_class_PCA.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "下面這個不要動，是在觀察漲跌標準差用的"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>future_5min_change</th>\n",
       "      <th>future_10min_change</th>\n",
       "      <th>future_15min_change</th>\n",
       "      <th>future_30min_change</th>\n",
       "      <th>future_60min_change</th>\n",
       "      <th>future_90min_change</th>\n",
       "      <th>future_120min_change</th>\n",
       "      <th>future_180min_change</th>\n",
       "      <th>future_240min_change</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>18712.000000</td>\n",
       "      <td>18707.000000</td>\n",
       "      <td>18702.000000</td>\n",
       "      <td>18687.000000</td>\n",
       "      <td>18657.000000</td>\n",
       "      <td>18627.000000</td>\n",
       "      <td>18597.000000</td>\n",
       "      <td>18537.000000</td>\n",
       "      <td>18477.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.002100</td>\n",
       "      <td>0.004154</td>\n",
       "      <td>0.006206</td>\n",
       "      <td>0.012331</td>\n",
       "      <td>0.023995</td>\n",
       "      <td>0.035968</td>\n",
       "      <td>0.047988</td>\n",
       "      <td>0.072643</td>\n",
       "      <td>0.098254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.137146</td>\n",
       "      <td>0.190865</td>\n",
       "      <td>0.232627</td>\n",
       "      <td>0.322724</td>\n",
       "      <td>0.448382</td>\n",
       "      <td>0.550104</td>\n",
       "      <td>0.641025</td>\n",
       "      <td>0.797345</td>\n",
       "      <td>0.929750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-1.774301</td>\n",
       "      <td>-1.746236</td>\n",
       "      <td>-1.753214</td>\n",
       "      <td>-2.177889</td>\n",
       "      <td>-2.276888</td>\n",
       "      <td>-2.900994</td>\n",
       "      <td>-2.764514</td>\n",
       "      <td>-4.076634</td>\n",
       "      <td>-4.893189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-0.050397</td>\n",
       "      <td>-0.071292</td>\n",
       "      <td>-0.087100</td>\n",
       "      <td>-0.128220</td>\n",
       "      <td>-0.199788</td>\n",
       "      <td>-0.250610</td>\n",
       "      <td>-0.278806</td>\n",
       "      <td>-0.322662</td>\n",
       "      <td>-0.342064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.002587</td>\n",
       "      <td>0.007081</td>\n",
       "      <td>0.009454</td>\n",
       "      <td>0.019969</td>\n",
       "      <td>0.038950</td>\n",
       "      <td>0.060525</td>\n",
       "      <td>0.080980</td>\n",
       "      <td>0.112165</td>\n",
       "      <td>0.147506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.060851</td>\n",
       "      <td>0.088304</td>\n",
       "      <td>0.109730</td>\n",
       "      <td>0.171596</td>\n",
       "      <td>0.260453</td>\n",
       "      <td>0.337419</td>\n",
       "      <td>0.427545</td>\n",
       "      <td>0.604783</td>\n",
       "      <td>0.721625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.977869</td>\n",
       "      <td>1.062134</td>\n",
       "      <td>1.340572</td>\n",
       "      <td>1.549550</td>\n",
       "      <td>1.962723</td>\n",
       "      <td>2.280553</td>\n",
       "      <td>2.254635</td>\n",
       "      <td>2.385865</td>\n",
       "      <td>2.768850</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       future_5min_change  future_10min_change  future_15min_change  \\\n",
       "count        18712.000000         18707.000000         18702.000000   \n",
       "mean             0.002100             0.004154             0.006206   \n",
       "std              0.137146             0.190865             0.232627   \n",
       "min             -1.774301            -1.746236            -1.753214   \n",
       "25%             -0.050397            -0.071292            -0.087100   \n",
       "50%              0.002587             0.007081             0.009454   \n",
       "75%              0.060851             0.088304             0.109730   \n",
       "max              0.977869             1.062134             1.340572   \n",
       "\n",
       "       future_30min_change  future_60min_change  future_90min_change  \\\n",
       "count         18687.000000         18657.000000         18627.000000   \n",
       "mean              0.012331             0.023995             0.035968   \n",
       "std               0.322724             0.448382             0.550104   \n",
       "min              -2.177889            -2.276888            -2.900994   \n",
       "25%              -0.128220            -0.199788            -0.250610   \n",
       "50%               0.019969             0.038950             0.060525   \n",
       "75%               0.171596             0.260453             0.337419   \n",
       "max               1.549550             1.962723             2.280553   \n",
       "\n",
       "       future_120min_change  future_180min_change  future_240min_change  \n",
       "count          18597.000000          18537.000000          18477.000000  \n",
       "mean               0.047988              0.072643              0.098254  \n",
       "std                0.641025              0.797345              0.929750  \n",
       "min               -2.764514             -4.076634             -4.893189  \n",
       "25%               -0.278806             -0.322662             -0.342064  \n",
       "50%                0.080980              0.112165              0.147506  \n",
       "75%                0.427545              0.604783              0.721625  \n",
       "max                2.254635              2.385865              2.768850  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#觀察漲跌的標準差是多少，用來決定class的門檻值\n",
    "data[\n",
    "    [\n",
    "        \"future_5min_change\",\n",
    "        \"future_10min_change\",\n",
    "        \"future_15min_change\",\n",
    "        \"future_30min_change\",\n",
    "        \"future_60min_change\",\n",
    "        \"future_90min_change\",\n",
    "        \"future_120min_change\",\n",
    "        \"future_180min_change\",\n",
    "        \"future_240min_change\",\n",
    "    ]\n",
    "].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df=data.copy()\n",
    "data_df['datetime']=pd.to_datetime(data_df['datetime'])\n",
    "# 移除15:00~17:00以及03:00~04:00的資料\n",
    "data_df_清洗 = data_df[\n",
    "    (data_df[\"datetime\"].dt.time >= pd.to_datetime(\"17:00:00\").time())\n",
    "    | (data_df[\"datetime\"].dt.time <= pd.to_datetime(\"03:00:00\").time())\n",
    "]\n",
    "# data.drop([\"datetime\"], axis=1, inplace=True)\n",
    "\n",
    "numeric_cols = data_df_清洗.select_dtypes(include=[\"number\"]).columns\n",
    "filtered_rows = data_df_清洗[(data_df_清洗[numeric_cols] > 999999999).any(axis=1)]\n",
    "# data_df_清洗 = filtered_rows.dropna()\n",
    "\n",
    "# # 13873 row\n",
    "df_train = data_df_清洗.iloc[:10000]\n",
    "df_validation = data_df_清洗.iloc[10000:11000]\n",
    "df_predict = data_df_清洗.iloc[11000:11100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.columns[df_train.isna().any()].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'datetime',\n",
      "'future_5min_change',\n",
      "'future_10min_change',\n",
      "'future_15min_change',\n",
      "'future_30min_change',\n",
      "'future_60min_change',\n",
      "'future_90min_change',\n",
      "'future_120min_change',\n",
      "'future_180min_change',\n",
      "'future_240min_change',\n",
      "'PC1',\n",
      "'PC2',\n",
      "'PC3',\n",
      "'PC4',\n",
      "'PC5',\n",
      "'PC6',\n",
      "'PC7',\n",
      "'PC8',\n",
      "'PC9',\n",
      "'PC10',\n",
      "'PC11',\n",
      "'PC12',\n",
      "'PC13',\n",
      "'PC14',\n",
      "'PC15',\n",
      "'PC16',\n",
      "'PC17',\n",
      "'PC18',\n",
      "'PC19',\n",
      "'PC20',\n",
      "'PC21',\n",
      "'PC22',\n",
      "'PC23',\n",
      "'PC24',\n",
      "'PC25',\n",
      "'PC26',\n",
      "'PC27',\n",
      "'PC28',\n",
      "'PC29',\n",
      "'PC30',\n",
      "'PC31',\n",
      "'PC32',\n",
      "'PC33',\n",
      "'PC34',\n",
      "'PC35',\n",
      "'PC36',\n",
      "'PC37',\n"
     ]
    }
   ],
   "source": [
    "for col in data_df_清洗.columns:\n",
    "    print(f\"'{col}',\")\n",
    "# print(list(data_df_清洗.columns))\n",
    "\n",
    "# pd.DataFrame(data_df_清洗.columns, columns=[\"Column Names\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 特徵擇一"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['PC1', 'PC2', 'PC3', 'PC4', 'PC5', 'PC6', 'PC7', 'PC8', 'PC9', 'PC10', 'PC11', 'PC12', 'PC13', 'PC14', 'PC15', 'PC16', 'PC17', 'PC18', 'PC19', 'PC20', 'PC21', 'PC22', 'PC23', 'PC24', 'PC25', 'PC26', 'PC27', 'PC28', 'PC29', 'PC30', 'PC31', 'PC32', 'PC33', 'PC34', 'PC35', 'PC36', 'PC37']\n"
     ]
    }
   ],
   "source": [
    "targets = [\n",
    "    \"future_5min_change\",\n",
    "    \"future_10min_change\",\n",
    "    \"future_15min_change\",\n",
    "    \"future_30min_change\",\n",
    "    \"future_60min_change\",\n",
    "    \"future_90min_change\",\n",
    "    \"future_120min_change\",\n",
    "    \"future_180min_change\",\n",
    "    \"future_240min_change\",\n",
    "]\n",
    "features = list(data_df_清洗.drop(targets, axis=1).columns)[1:]\n",
    "print(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 假設 data 是您的 dataframe\n",
    "# 先定義特徵和目標變數\n",
    "features = [\n",
    "    \"open\",\n",
    "    \"high\",\n",
    "    \"low\",\n",
    "    \"close\",\n",
    "    \"volume\",\n",
    "    \"mym_ma_15\",\n",
    "    \"mym_ma_slope_15\",\n",
    "    \"mym_ma_30\",\n",
    "    \"mym_ma_slope_30\",\n",
    "    \"mym_ma_60\",\n",
    "    \"mym_ma_slope_60\",\n",
    "    \"mym_ma_120\",\n",
    "    \"mym_ma_slope_120\",\n",
    "    \"mym_ma_360\",\n",
    "    \"mym_ma_slope_360\",\n",
    "    \"mym_ma_1440\",\n",
    "    \"mym_ma_slope_1440\",\n",
    "    \"mym_ma_7200\",\n",
    "    \"mym_ma_slope_7200\",\n",
    "    # \"mym_volume_ma_15\",\n",
    "    # \"mym_volume_ma_slope_15\",\n",
    "    \"mym_volume_ma_30\",\n",
    "    # \"mym_volume_ma_slope_30\",\n",
    "    \"mym_volume_ma_60\",\n",
    "    \"mym_volume_ma_slope_60\",\n",
    "    \"mym_volume_ma_120\",\n",
    "    \"mym_volume_ma_slope_120\",\n",
    "    \"mym_volume_ma_360\",\n",
    "    \"mym_volume_ma_slope_360\",\n",
    "    \"mym_volume_ma_720\",\n",
    "    \"mym_volume_ma_slope_720\",\n",
    "    \"mym_volume_ma_1440\",\n",
    "    \"mym_volume_ma_slope_1440\",\n",
    "    \"mym_volume_ma_7200\",\n",
    "    \"mym_volume_ma_slope_7200\",\n",
    "    \"vwap_cumulative_volume\",\n",
    "    \"vwap_cumulative_volume_price\",\n",
    "    \"VWAP\",\n",
    "    \"VWAP_30漲跌幅\",\n",
    "    \"VWAP_60漲跌幅\",\n",
    "    \"ATR_14\",\n",
    "    \"KC_upper\",\n",
    "    \"KC_lower\",\n",
    "    \"ATR_21\",\n",
    "    \"ATR_28\",\n",
    "    \"ATR_42\",\n",
    "    \"OBV\",\n",
    "    \"14KD_lowest_low\",\n",
    "    \"14KD_highest_high\",\n",
    "    \"14%K\",\n",
    "    \"14KD_%D\",\n",
    "    \"28KD_lowest_low\",\n",
    "    \"28KD_highest_high\",\n",
    "    \"28%K\",\n",
    "    \"28KD_%D\",\n",
    "    \"RSI\",\n",
    "    \"MACD\",\n",
    "    \"Signal_Line\",\n",
    "    \"MACD_Histogram\",\n",
    "    \"BB_upper\",\n",
    "    \"BB_lower\",\n",
    "    # \"return_15m\",\n",
    "    # \"high_return_15m\",\n",
    "    # \"low_return_15m\",\n",
    "    \"return_30m\",\n",
    "    \"high_return_30m\",\n",
    "    \"low_return_30m\",\n",
    "    \"return_60m\",\n",
    "    \"high_return_60m\",\n",
    "    \"low_return_60m\",\n",
    "    \"return_120m\",\n",
    "    \"high_return_120m\",\n",
    "    \"low_return_120m\",\n",
    "    \"return_240m\",\n",
    "    \"high_return_240m\",\n",
    "    \"low_return_240m\",\n",
    "    \"minutes_from_open\",\n",
    "    \"距離2130的時間差\",\n",
    "    \"YM五分內最大1min成交量\",\n",
    "    \"YM五分內成交總筆數\",\n",
    "    \"ES close\",\n",
    "    \"ES volume\",\n",
    "    \"ES count\",\n",
    "    \"VIX近 close\",\n",
    "    # \"VIX近 volume\",\n",
    "    # \"VIX近 count\",\n",
    "    \"VIX_近 480分漲跌幅\",\n",
    "    \"VIX_近 240分漲跌幅\",\n",
    "    \"VIX_近 120分漲跌幅\",\n",
    "    \"VIX_近 60分漲跌幅\",\n",
    "    \"VIX_近 30分漲跌幅\",\n",
    "    \"ZN close\",\n",
    "    # \"ZN volume\",\n",
    "    # \"ZN count\",\n",
    "    \"ZN 30分鐘漲跌幅\",\n",
    "    \"ZN 60分鐘漲跌幅\",\n",
    "    \"RTY close\",\n",
    "    # \"RTY volume\",\n",
    "    # \"RTY count\",\n",
    "    \"RTY 30分鐘漲跌幅\",\n",
    "    \"RTY 60分鐘漲跌幅\",\n",
    "    \"NQ close\",\n",
    "    # \"NQ volume\",\n",
    "    # \"NQ count\",\n",
    "    \"NQ 30分鐘漲跌幅\",\n",
    "    \"NQ 60分鐘漲跌幅\",\n",
    "    \"DX close\",\n",
    "    # \"DX volume\",\n",
    "    # \"DX count\",\n",
    "    \"DX 30分鐘漲跌幅\",\n",
    "    \"DX 60分鐘漲跌幅\",\n",
    "]\n",
    "targets = [\n",
    "    \"future_5min_change\",\n",
    "    \"future_10min_change\",\n",
    "    \"future_15min_change\",\n",
    "    \"future_30min_change\",\n",
    "    \"future_60min_change\",\n",
    "    \"future_90min_change\",\n",
    "    \"future_120min_change\",\n",
    "    \"future_180min_change\",\n",
    "    \"future_240min_change\",\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 分類器 --可"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "\n",
    "class TimeSeriesClassifier:\n",
    "    def __init__(self, window_size=10):\n",
    "        \"\"\"\n",
    "        初始化時間序列分類器\n",
    "        \"\"\"\n",
    "        self.window_size = window_size\n",
    "        self.model = None\n",
    "        self.features = None\n",
    "        self.label_encoder = LabelEncoder()\n",
    "\n",
    "    def create_flattened_features(\n",
    "        self, df, features, target, start_idx=None, end_idx=None\n",
    "    ):\n",
    "        if start_idx is None:\n",
    "            start_idx = self.window_size\n",
    "        if end_idx is None:\n",
    "            end_idx = len(df)\n",
    "\n",
    "        flattened_data = []\n",
    "        flattened_labels = []\n",
    "\n",
    "        for i in range(start_idx, end_idx):\n",
    "            # 檢查時間間隔是否連續\n",
    "            if df['datetime'].iloc[i] - df['datetime'].iloc[i - 1] != pd.Timedelta(minutes=5):\n",
    "                continue  # 如果不連續，跳過該行\n",
    "\n",
    "            historical_data = df[features].iloc[i - self.window_size: i]\n",
    "            flattened_sample = historical_data.values.flatten()\n",
    "            flattened_data.append(flattened_sample)\n",
    "            flattened_labels.append(df[target].iloc[i])\n",
    "\n",
    "        X_flattened = np.array(flattened_data)\n",
    "        y_flattened = self.label_encoder.fit_transform(flattened_labels)\n",
    "\n",
    "        return X_flattened, y_flattened\n",
    "\n",
    "\n",
    "    def train(self, df, features, target, val_start_idx=None):\n",
    "        self.features = features\n",
    "\n",
    "        if val_start_idx is None:\n",
    "            val_start_idx = int(len(df) * 0.8)\n",
    "\n",
    "        X_train, y_train = self.create_flattened_features(\n",
    "            df, features, target, start_idx=self.window_size, end_idx=val_start_idx\n",
    "        )\n",
    "\n",
    "        X_val, y_val = self.create_flattened_features(\n",
    "            df, features, target, start_idx=val_start_idx, end_idx=len(df)\n",
    "        )\n",
    "\n",
    "        n_classes = len(np.unique(y_train))\n",
    "\n",
    "        params = {\n",
    "            \"objective\": \"multiclass\",\n",
    "            \"num_class\": n_classes,\n",
    "            \"metric\": \"multi_logloss\",\n",
    "            \"boosting_type\": \"gbdt\",\n",
    "            \"learning_rate\": 0.01,\n",
    "            \"num_leaves\": 31,\n",
    "            \"verbose\": -1,\n",
    "            \"colsample_bytree\": 0.8,\n",
    "            \"subsample\": 0.8,\n",
    "            # \"min_child_samples\": 40,\n",
    "        }\n",
    "\n",
    "        train_data = lgb.Dataset(X_train, label=y_train)\n",
    "        val_data = lgb.Dataset(X_val, label=y_val, reference=train_data)\n",
    "\n",
    "        self.model = lgb.train(\n",
    "            params,\n",
    "            train_data,\n",
    "            valid_sets=[train_data, val_data],\n",
    "            callbacks=[\n",
    "                lgb.log_evaluation(period=0),\n",
    "                lgb.early_stopping(stopping_rounds=30),\n",
    "            ],\n",
    "        )\n",
    "\n",
    "        # Display feature importance after training\n",
    "        self.display_feature_importance()\n",
    "\n",
    "        return self\n",
    "\n",
    "    def display_feature_importance(self):\n",
    "        \"\"\"\n",
    "        顯示特徵重要性\n",
    "        \"\"\"\n",
    "        if self.model is None:\n",
    "            raise ValueError(\"模型尚未訓練，請先調用train方法\")\n",
    "\n",
    "        # 取得特徵重要性\n",
    "        feature_importance = self.model.feature_importance(importance_type='gain')  # 或 'split'\n",
    "        feature_names = self.features * self.window_size  # 每個特徵都會展開 window_size 次\n",
    "\n",
    "        # 將特徵重要性與特徵名稱轉換為 DataFrame\n",
    "        importance_df = pd.DataFrame({\n",
    "            'feature': feature_names,\n",
    "            'importance': feature_importance\n",
    "        })\n",
    "\n",
    "        # 顯示按重要性排序的特徵\n",
    "        importance_df = importance_df.groupby('feature')['importance'].sum().sort_values(ascending=False)\n",
    "        print(\"Feature Importance:\")\n",
    "        print(importance_df)\n",
    "        importance_df.to_csv(\"datas/模型報告/9.RTY-DX-NQ-ZN.csv\")\n",
    "        return importance_df\n",
    "    def validate_step(self, df, target, start_idx, end_idx):\n",
    "        y_true = []\n",
    "        y_pred = []\n",
    "\n",
    "        for i in range(start_idx, end_idx):\n",
    "            # 檢查時間間隔是否連續\n",
    "            if df['datetime'].iloc[i] - df['datetime'].iloc[i - 1] != pd.Timedelta(minutes=5):\n",
    "                continue  # 跳過非連續的時間點\n",
    "\n",
    "            X_val = df[self.features].iloc[i - self.window_size: i].values.flatten().reshape(1, -1)\n",
    "            current_true = df[target].iloc[i]\n",
    "            pred_proba = self.model.predict(X_val)\n",
    "            pred_class = np.argmax(pred_proba, axis=1)[0]\n",
    "            predicted_label = self.label_encoder.inverse_transform([pred_class])[0]\n",
    "\n",
    "            y_true.append(current_true)\n",
    "            y_pred.append(predicted_label)\n",
    "\n",
    "        return y_true, y_pred\n",
    "\n",
    "\n",
    "    def validate(self, df, targets):\n",
    "        \"\"\"\n",
    "        對多個目標進行驗證\n",
    "        \"\"\"\n",
    "        results = {}\n",
    "\n",
    "        for target in targets:\n",
    "            y_true, y_pred = self.validate_step(\n",
    "                df, target, start_idx=self.window_size, end_idx=len(df)\n",
    "            )\n",
    "\n",
    "            accuracy = accuracy_score(y_true, y_pred)\n",
    "            class_report = classification_report(y_true, y_pred)\n",
    "\n",
    "            print(f\"\\nValidation results for {target}:\")\n",
    "            print(f\"Accuracy: {accuracy:.4f}\")\n",
    "            print(\"Detailed Classification Report:\")\n",
    "            print(class_report)\n",
    "\n",
    "            results[target] = {\n",
    "                \"accuracy\": accuracy,\n",
    "                \"classification_report\": class_report,\n",
    "                \"predictions\": y_pred,\n",
    "            }\n",
    "\n",
    "        return results\n",
    "\n",
    "    def predict_step(self, df, start_idx, end_idx):\n",
    "        \"\"\"\n",
    "        逐步預測，確保只使用歷史數據\n",
    "        \"\"\"\n",
    "        predictions = []\n",
    "\n",
    "        for i in range(start_idx, end_idx):\n",
    "            # 只使用過去的數據\n",
    "            X_test = (\n",
    "                df[self.features]\n",
    "                .iloc[i - self.window_size : i]\n",
    "                .values.flatten()\n",
    "                .reshape(1, -1)\n",
    "            )\n",
    "\n",
    "            # 預測並轉換回原始標籤\n",
    "            pred_proba = self.model.predict(X_test)\n",
    "            pred_class = np.argmax(pred_proba, axis=1)[0]\n",
    "            predicted_label = self.label_encoder.inverse_transform([pred_class])[0]\n",
    "\n",
    "            predictions.append(predicted_label)\n",
    "\n",
    "        return predictions\n",
    "\n",
    "    def predict(self, df, targets):\n",
    "        \"\"\"\n",
    "        對多個目標進行預測\n",
    "        \"\"\"\n",
    "        if self.model is None:\n",
    "            raise ValueError(\"模型尚未訓練，請先調用train方法\")\n",
    "\n",
    "        predictions = {}\n",
    "\n",
    "        for target in targets:\n",
    "            pred_list = self.predict_step(\n",
    "                df, start_idx=self.window_size, end_idx=len(df)\n",
    "            )\n",
    "\n",
    "            predictions[target] = pred_list\n",
    "\n",
    "            # 如果有真實標籤，計算準確度\n",
    "            if target in df.columns:\n",
    "                true_values = df[target].iloc[self.window_size : len(df)].values\n",
    "                accuracy = accuracy_score(true_values, pred_list)\n",
    "                class_report = classification_report(true_values, pred_list)\n",
    "\n",
    "                print(f\"\\nPrediction results for {target}:\")\n",
    "                print(f\"Accuracy: {accuracy:.4f}\")\n",
    "                print(\"Detailed Classification Report:\")\n",
    "                print(class_report)\n",
    "\n",
    "        return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = [\n",
    "    \"future_5min_change\",\n",
    "    \"future_10min_change\",\n",
    "    \"future_15min_change\",\n",
    "    \"future_30min_change\",\n",
    "    \"future_60min_change\",\n",
    "    \"future_90min_change\",\n",
    "    \"future_120min_change\",\n",
    "    \"future_180min_change\",\n",
    "    \"future_240min_change\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 30 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\ttraining's multi_logloss: 0.863973\tvalid_1's multi_logloss: 1.04549\n",
      "Feature Importance:\n",
      "feature\n",
      "PC1     27273.943257\n",
      "PC8     10367.387690\n",
      "PC7      8259.626255\n",
      "PC26     5973.167596\n",
      "PC2      5970.807743\n",
      "PC15     5894.145748\n",
      "PC14     5837.385012\n",
      "PC29     5833.954493\n",
      "PC16     5655.564596\n",
      "PC4      5174.332921\n",
      "PC22     5081.915648\n",
      "PC24     4956.193942\n",
      "PC27     4420.587588\n",
      "PC11     4229.410151\n",
      "PC13     4217.974003\n",
      "PC31     4048.177816\n",
      "PC20     4046.856801\n",
      "PC5      4027.055633\n",
      "PC23     3949.685029\n",
      "PC10     3847.371077\n",
      "PC35     3523.586816\n",
      "PC12     3106.942549\n",
      "PC25     3069.560948\n",
      "PC9      2937.054996\n",
      "PC3      2501.854425\n",
      "PC21     2498.370744\n",
      "PC30     2456.090860\n",
      "PC37     2369.507179\n",
      "PC18     2045.096447\n",
      "PC34     1915.079872\n",
      "PC32     1897.085833\n",
      "PC17     1888.101696\n",
      "PC19     1784.496117\n",
      "PC6      1734.704953\n",
      "PC36     1562.025253\n",
      "PC33     1498.198621\n",
      "PC28      716.587718\n",
      "Name: importance, dtype: float64\n",
      "\n",
      "Validation results for future_10min_change:\n",
      "Accuracy: 0.4073\n",
      "Detailed Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.16      0.09      0.11       235\n",
      "         0.0       0.43      0.83      0.56       384\n",
      "         1.0       0.54      0.17      0.26       363\n",
      "\n",
      "    accuracy                           0.41       982\n",
      "   macro avg       0.38      0.36      0.31       982\n",
      "weighted avg       0.40      0.41      0.34       982\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 使用示例\n",
    "# 初始化分類器\n",
    "classifier = TimeSeriesClassifier(window_size=10)\n",
    "\n",
    "# 訓練模型\n",
    "# 使用前80%的數據訓練，後20%驗證\n",
    "train_end_idx = int(len(df_train) * 0.8)\n",
    "target_n = 1\n",
    "classifier.train(df_train, features, targets[target_n], val_start_idx=train_end_idx)\n",
    "\n",
    "# 驗證模型\n",
    "validation_results = classifier.validate(\n",
    "    df_validation, targets[target_n : target_n + 1]\n",
    ")\n",
    "\n",
    "# 預測\n",
    "# predictions = classifier.predict(df_predict, targets)\n",
    "# +-0.05%\n",
    "# 0:0.41\n",
    "# 1:0.39\n",
    "# 2:0.39\n",
    "# 3:0.24\n",
    "# 4:0.30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 分類器調參數-CPU多執行緒"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from itertools import product\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "class TimeSeriesClassifier:\n",
    "    def __init__(self, window_size=10):\n",
    "        \"\"\"\n",
    "        初始化時間序列分類器\n",
    "        \"\"\"\n",
    "        self.window_size = window_size\n",
    "        self.model = None\n",
    "        self.features = None\n",
    "        self.label_encoder = LabelEncoder()\n",
    "        self.best_params = None\n",
    "        self.best_score = float(\"-inf\")\n",
    "\n",
    "    def create_flattened_features(\n",
    "        self, df, features, target, start_idx=None, end_idx=None\n",
    "    ):\n",
    "        \"\"\"\n",
    "        創建扁平化特徵，可以指定開始和結束索引\n",
    "        \"\"\"\n",
    "        if start_idx is None:\n",
    "            start_idx = self.window_size\n",
    "        if end_idx is None:\n",
    "            end_idx = len(df)\n",
    "\n",
    "        flattened_data = []\n",
    "        flattened_labels = []\n",
    "\n",
    "        for i in range(start_idx, end_idx):\n",
    "            historical_data = df[features].iloc[i - self.window_size : i]\n",
    "            flattened_sample = historical_data.values.flatten()\n",
    "            flattened_data.append(flattened_sample)\n",
    "            flattened_labels.append(df[target].iloc[i])\n",
    "\n",
    "        X_flattened = np.array(flattened_data)\n",
    "        y_flattened = self.label_encoder.fit_transform(flattened_labels)\n",
    "\n",
    "        return X_flattened, y_flattened\n",
    "\n",
    "    def _train_with_params(self, X_train, y_train, X_val, y_val, params):\n",
    "        \"\"\"\n",
    "        使用指定參數訓練模型\n",
    "        \"\"\"\n",
    "        train_data = lgb.Dataset(X_train, label=y_train)\n",
    "        val_data = lgb.Dataset(X_val, label=y_val, reference=train_data)\n",
    "\n",
    "        model = lgb.train(\n",
    "            params,\n",
    "            train_data,\n",
    "            valid_sets=[train_data, val_data],\n",
    "            callbacks=[\n",
    "                lgb.log_evaluation(period=0),\n",
    "                lgb.early_stopping(stopping_rounds=30),\n",
    "            ],\n",
    "        )\n",
    "\n",
    "        # 使用驗證集評估模型\n",
    "        val_pred = np.argmax(model.predict(X_val), axis=1)\n",
    "        val_score = accuracy_score(y_val, val_pred)\n",
    "\n",
    "        return model, val_score, params\n",
    "\n",
    "    def tune_parameters(self, df, features, target, val_start_idx=None, n_jobs=-1):\n",
    "        \"\"\"\n",
    "        使用多執行緒進行參數調優\n",
    "        \"\"\"\n",
    "        self.features = features\n",
    "\n",
    "        if val_start_idx is None:\n",
    "            val_start_idx = int(len(df) * 0.8)\n",
    "\n",
    "        # 準備訓練集和驗證集\n",
    "        X_train, y_train = self.create_flattened_features(\n",
    "            df, features, target, start_idx=self.window_size, end_idx=val_start_idx\n",
    "        )\n",
    "\n",
    "        X_val, y_val = self.create_flattened_features(\n",
    "            df, features, target, start_idx=val_start_idx, end_idx=len(df)\n",
    "        )\n",
    "\n",
    "        n_classes = len(np.unique(y_train))\n",
    "\n",
    "        # 定義參數網格\n",
    "        param_grid = {\n",
    "            \"learning_rate\": [0.01, 0.005, 0.001],\n",
    "            \"num_leaves\": [31, 40, 50],\n",
    "            \"min_child_samples\": [20, 30, 40],\n",
    "            \"subsample\": [0.8, 0.9, 1.0],\n",
    "            \"colsample_bytree\": [0.8, 0.9, 1.0],\n",
    "        }\n",
    "\n",
    "        # 生成所有參數組合\n",
    "        param_combinations = [\n",
    "            dict(zip(param_grid.keys(), v)) for v in product(*param_grid.values())\n",
    "        ]\n",
    "\n",
    "        # 為每個參數組合添加固定參數\n",
    "        base_params = {\n",
    "            \"objective\": \"multiclass\",\n",
    "            \"num_class\": n_classes,\n",
    "            \"metric\": \"multi_logloss\",\n",
    "            \"boosting_type\": \"gbdt\",\n",
    "            \"verbose\": -1,\n",
    "        }\n",
    "\n",
    "        for params in param_combinations:\n",
    "            params.update(base_params)\n",
    "\n",
    "        best_model = None\n",
    "        results = []\n",
    "\n",
    "        # 使用線程池進行並行訓練\n",
    "        with ThreadPoolExecutor(max_workers=n_jobs if n_jobs > 0 else None) as executor:\n",
    "            future_to_params = {\n",
    "                executor.submit(\n",
    "                    self._train_with_params, X_train, y_train, X_val, y_val, params\n",
    "                ): params\n",
    "                for params in param_combinations\n",
    "            }\n",
    "\n",
    "            for future in as_completed(future_to_params):\n",
    "                model, score, params = future.result()\n",
    "                results.append((score, params, model))\n",
    "\n",
    "                if score > self.best_score:\n",
    "                    self.best_score = score\n",
    "                    self.best_params = params\n",
    "                    best_model = model\n",
    "                    print(f\"\\nNew best score: {score:.4f}\")\n",
    "                    print(\n",
    "                        \"Parameters:\",\n",
    "                        {k: v for k, v in params.items() if k not in base_params},\n",
    "                    )\n",
    "\n",
    "        # 使用最佳參數更新模型\n",
    "        self.model = best_model\n",
    "\n",
    "        # 將結果整理成DataFrame\n",
    "        results_df = pd.DataFrame(\n",
    "            [\n",
    "                {\n",
    "                    **{k: v for k, v in params.items() if k not in base_params},\n",
    "                    \"score\": score,\n",
    "                }\n",
    "                for score, params, _ in results\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        return results_df\n",
    "\n",
    "    def train(self, df, features, target, val_start_idx=None):\n",
    "        \"\"\"\n",
    "        使用最佳參數訓練模型\n",
    "        \"\"\"\n",
    "        if self.best_params is None:\n",
    "            print(\"Warning: No tuned parameters found. Using default parameters.\")\n",
    "            return super().train(df, features, target, val_start_idx)\n",
    "\n",
    "        self.features = features\n",
    "\n",
    "        if val_start_idx is None:\n",
    "            val_start_idx = int(len(df) * 0.8)\n",
    "\n",
    "        X_train, y_train = self.create_flattened_features(\n",
    "            df, features, target, start_idx=self.window_size, end_idx=val_start_idx\n",
    "        )\n",
    "\n",
    "        X_val, y_val = self.create_flattened_features(\n",
    "            df, features, target, start_idx=val_start_idx, end_idx=len(df)\n",
    "        )\n",
    "\n",
    "        train_data = lgb.Dataset(X_train, label=y_train)\n",
    "        val_data = lgb.Dataset(X_val, label=y_val, reference=train_data)\n",
    "\n",
    "        self.model = lgb.train(\n",
    "            self.best_params,\n",
    "            train_data,\n",
    "            valid_sets=[train_data, val_data],\n",
    "            callbacks=[\n",
    "                lgb.log_evaluation(period=0),\n",
    "                lgb.early_stopping(stopping_rounds=30),\n",
    "            ],\n",
    "        )\n",
    "\n",
    "        return self\n",
    "\n",
    "    def validate_step(self, df, target, start_idx, end_idx):\n",
    "        \"\"\"\n",
    "        逐步驗證，確保只使用歷史數據\n",
    "        \"\"\"\n",
    "        if self.model is None:\n",
    "            raise ValueError(\"模型尚未訓練，請先調用train方法\")\n",
    "\n",
    "        y_true = []\n",
    "        y_pred = []\n",
    "\n",
    "        for i in range(start_idx, end_idx):\n",
    "            X_val = (\n",
    "                df[self.features]\n",
    "                .iloc[i - self.window_size : i]\n",
    "                .values.flatten()\n",
    "                .reshape(1, -1)\n",
    "            )\n",
    "            current_true = df[target].iloc[i]\n",
    "\n",
    "            pred_proba = self.model.predict(X_val)\n",
    "            pred_class = np.argmax(pred_proba, axis=1)[0]\n",
    "            predicted_label = self.label_encoder.inverse_transform([pred_class])[0]\n",
    "\n",
    "            y_true.append(current_true)\n",
    "            y_pred.append(predicted_label)\n",
    "\n",
    "        return y_true, y_pred\n",
    "\n",
    "    def validate(self, df, targets):\n",
    "        \"\"\"\n",
    "        對多個目標進行驗證\n",
    "        \"\"\"\n",
    "        results = {}\n",
    "\n",
    "        for target in targets:\n",
    "            y_true, y_pred = self.validate_step(\n",
    "                df, target, start_idx=self.window_size, end_idx=len(df)\n",
    "            )\n",
    "\n",
    "            accuracy = accuracy_score(y_true, y_pred)\n",
    "            class_report = classification_report(y_true, y_pred)\n",
    "\n",
    "            print(f\"\\nValidation results for {target}:\")\n",
    "            print(f\"Accuracy: {accuracy:.4f}\")\n",
    "            print(\"Detailed Classification Report:\")\n",
    "            print(class_report)\n",
    "\n",
    "            results[target] = {\n",
    "                \"accuracy\": accuracy,\n",
    "                \"classification_report\": class_report,\n",
    "                \"predictions\": y_pred,\n",
    "            }\n",
    "\n",
    "        return results\n",
    "\n",
    "    def predict_step(self, df, start_idx, end_idx):\n",
    "        \"\"\"\n",
    "        逐步預測，確保只使用歷史數據\n",
    "        \"\"\"\n",
    "        predictions = []\n",
    "\n",
    "        for i in range(start_idx, end_idx):\n",
    "            X_test = (\n",
    "                df[self.features]\n",
    "                .iloc[i - self.window_size : i]\n",
    "                .values.flatten()\n",
    "                .reshape(1, -1)\n",
    "            )\n",
    "\n",
    "            pred_proba = self.model.predict(X_test)\n",
    "            pred_class = np.argmax(pred_proba, axis=1)[0]\n",
    "            predicted_label = self.label_encoder.inverse_transform([pred_class])[0]\n",
    "\n",
    "            predictions.append(predicted_label)\n",
    "\n",
    "        return predictions\n",
    "\n",
    "    def predict(self, df, targets):\n",
    "        \"\"\"\n",
    "        對多個目標進行預測\n",
    "        \"\"\"\n",
    "        if self.model is None:\n",
    "            raise ValueError(\"模型尚未訓練，請先調用train方法\")\n",
    "\n",
    "        predictions = {}\n",
    "\n",
    "        for target in targets:\n",
    "            pred_list = self.predict_step(\n",
    "                df, start_idx=self.window_size, end_idx=len(df)\n",
    "            )\n",
    "\n",
    "            predictions[target] = pred_list\n",
    "\n",
    "            if target in df.columns:\n",
    "                true_values = df[target].iloc[self.window_size : len(df)].values\n",
    "                accuracy = accuracy_score(true_values, pred_list)\n",
    "                class_report = classification_report(true_values, pred_list)\n",
    "\n",
    "                print(f\"\\nPrediction results for {target}:\")\n",
    "                print(f\"Accuracy: {accuracy:.4f}\")\n",
    "                print(\"Detailed Classification Report:\")\n",
    "                print(class_report)\n",
    "\n",
    "        return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 30 rounds\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[11]\ttraining's multi_logloss: 0.979131\tvalid_1's multi_logloss: 1.12964\n",
      "Early stopping, best iteration is:\n",
      "[10]\ttraining's multi_logloss: 0.986817\tvalid_1's multi_logloss: 1.12921\n",
      "\n",
      "New best score: 0.3230\n",
      "Parameters: {'learning_rate': 0.01, 'num_leaves': 31, 'min_child_samples': 20, 'subsample': 0.8, 'colsample_bytree': 0.9}\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[16]\ttraining's multi_logloss: 0.944241\tvalid_1's multi_logloss: 1.1312\n",
      "Early stopping, best iteration is:\n",
      "[16]\ttraining's multi_logloss: 0.944241\tvalid_1's multi_logloss: 1.1312\n",
      "\n",
      "New best score: 0.3555\n",
      "Parameters: {'learning_rate': 0.01, 'num_leaves': 31, 'min_child_samples': 20, 'subsample': 0.9, 'colsample_bytree': 0.8}\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[11]\ttraining's multi_logloss: 0.979131\tvalid_1's multi_logloss: 1.12964\n",
      "Early stopping, best iteration is:\n",
      "[10]\ttraining's multi_logloss: 0.986817\tvalid_1's multi_logloss: 1.12921\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[11]\ttraining's multi_logloss: 0.979131\tvalid_1's multi_logloss: 1.12964\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[16]\ttraining's multi_logloss: 0.944241\tvalid_1's multi_logloss: 1.1312\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[7]\ttraining's multi_logloss: 1.00986\tvalid_1's multi_logloss: 1.13399\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[10]\ttraining's multi_logloss: 0.986817\tvalid_1's multi_logloss: 1.12921\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[10]\ttraining's multi_logloss: 0.986844\tvalid_1's multi_logloss: 1.13166\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[10]\ttraining's multi_logloss: 0.986911\tvalid_1's multi_logloss: 1.13122\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[7]\ttraining's multi_logloss: 1.00986\tvalid_1's multi_logloss: 1.13399\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[10]\ttraining's multi_logloss: 0.986844\tvalid_1's multi_logloss: 1.13166\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[10]\ttraining's multi_logloss: 0.986911\tvalid_1's multi_logloss: 1.13122\n",
      "Early stopping, best iteration is:\n",
      "[7]\ttraining's multi_logloss: 1.00986\tvalid_1's multi_logloss: 1.13399\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[10]\ttraining's multi_logloss: 0.986844\tvalid_1's multi_logloss: 1.13166\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[10]\ttraining's multi_logloss: 0.986911\tvalid_1's multi_logloss: 1.13122\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[9]\ttraining's multi_logloss: 0.994985\tvalid_1's multi_logloss: 1.13186\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[9]\ttraining's multi_logloss: 0.994975\tvalid_1's multi_logloss: 1.13173\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[19]\ttraining's multi_logloss: 0.925543\tvalid_1's multi_logloss: 1.13417\n",
      "\n",
      "New best score: 0.3825\n",
      "Parameters: {'learning_rate': 0.01, 'num_leaves': 31, 'min_child_samples': 40, 'subsample': 0.8, 'colsample_bytree': 0.8}\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[9]\ttraining's multi_logloss: 0.994985\tvalid_1's multi_logloss: 1.13186\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[19]\ttraining's multi_logloss: 0.925543\tvalid_1's multi_logloss: 1.13417\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[9]\ttraining's multi_logloss: 0.994975\tvalid_1's multi_logloss: 1.13173\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[9]\ttraining's multi_logloss: 0.994985\tvalid_1's multi_logloss: 1.13186\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[9]\ttraining's multi_logloss: 0.994975\tvalid_1's multi_logloss: 1.13173\n",
      "Early stopping, best iteration is:\n",
      "[19]\ttraining's multi_logloss: 0.925543\tvalid_1's multi_logloss: 1.13417\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[11]\ttraining's multi_logloss: 0.968914\tvalid_1's multi_logloss: 1.12553\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[23]\ttraining's multi_logloss: 0.880352\tvalid_1's multi_logloss: 1.12684\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[13]\ttraining's multi_logloss: 0.953359\tvalid_1's multi_logloss: 1.12278\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[23]\ttraining's multi_logloss: 0.880352\tvalid_1's multi_logloss: 1.12684\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[11]\ttraining's multi_logloss: 0.968914\tvalid_1's multi_logloss: 1.12553\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[13]\ttraining's multi_logloss: 0.953359\tvalid_1's multi_logloss: 1.12278\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[11]\ttraining's multi_logloss: 0.968914\tvalid_1's multi_logloss: 1.12553\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[23]\ttraining's multi_logloss: 0.880352\tvalid_1's multi_logloss: 1.12684\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[13]\ttraining's multi_logloss: 0.953359\tvalid_1's multi_logloss: 1.12278\n",
      "Early stopping, best iteration is:\n",
      "[12]\ttraining's multi_logloss: 0.962383\tvalid_1's multi_logloss: 1.1299\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[10]\ttraining's multi_logloss: 0.978063\tvalid_1's multi_logloss: 1.12767\n",
      "Early stopping, best iteration is:\n",
      "[14]\ttraining's multi_logloss: 0.946123\tvalid_1's multi_logloss: 1.12656\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[12]\ttraining's multi_logloss: 0.962383\tvalid_1's multi_logloss: 1.1299\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[14]\ttraining's multi_logloss: 0.946123\tvalid_1's multi_logloss: 1.12656\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[10]\ttraining's multi_logloss: 0.978063\tvalid_1's multi_logloss: 1.12767\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[12]\ttraining's multi_logloss: 0.962383\tvalid_1's multi_logloss: 1.1299\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[14]\ttraining's multi_logloss: 0.946123\tvalid_1's multi_logloss: 1.12656\n",
      "Early stopping, best iteration is:\n",
      "[10]\ttraining's multi_logloss: 0.978063\tvalid_1's multi_logloss: 1.12767\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[22]\ttraining's multi_logloss: 0.890398\tvalid_1's multi_logloss: 1.128\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[25]\ttraining's multi_logloss: 0.869712\tvalid_1's multi_logloss: 1.12728\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[21]\ttraining's multi_logloss: 0.896279\tvalid_1's multi_logloss: 1.12674\n",
      "Early stopping, best iteration is:\n",
      "[22]\ttraining's multi_logloss: 0.890398\tvalid_1's multi_logloss: 1.128\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[25]\ttraining's multi_logloss: 0.869712\tvalid_1's multi_logloss: 1.12728\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[21]\ttraining's multi_logloss: 0.896279\tvalid_1's multi_logloss: 1.12674\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[22]\ttraining's multi_logloss: 0.890398\tvalid_1's multi_logloss: 1.128\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[25]\ttraining's multi_logloss: 0.869712\tvalid_1's multi_logloss: 1.12728\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[21]\ttraining's multi_logloss: 0.896279\tvalid_1's multi_logloss: 1.12674\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[23]\ttraining's multi_logloss: 0.863896\tvalid_1's multi_logloss: 1.11926\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[21]\ttraining's multi_logloss: 0.878437\tvalid_1's multi_logloss: 1.11808\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[25]\ttraining's multi_logloss: 0.848809\tvalid_1's multi_logloss: 1.12081\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[23]\ttraining's multi_logloss: 0.863896\tvalid_1's multi_logloss: 1.11926\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[21]\ttraining's multi_logloss: 0.878437\tvalid_1's multi_logloss: 1.11808\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[25]\ttraining's multi_logloss: 0.848809\tvalid_1's multi_logloss: 1.12081\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[23]\ttraining's multi_logloss: 0.863896\tvalid_1's multi_logloss: 1.11926\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[21]\ttraining's multi_logloss: 0.878437\tvalid_1's multi_logloss: 1.11808\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[25]\ttraining's multi_logloss: 0.848809\tvalid_1's multi_logloss: 1.12081\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[20]\ttraining's multi_logloss: 0.888319\tvalid_1's multi_logloss: 1.1197\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[21]\ttraining's multi_logloss: 0.880365\tvalid_1's multi_logloss: 1.11793\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[17]\ttraining's multi_logloss: 0.911063\tvalid_1's multi_logloss: 1.11698\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[20]\ttraining's multi_logloss: 0.888319\tvalid_1's multi_logloss: 1.1197\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[21]\ttraining's multi_logloss: 0.880365\tvalid_1's multi_logloss: 1.11793\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[17]\ttraining's multi_logloss: 0.911063\tvalid_1's multi_logloss: 1.11698\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[20]\ttraining's multi_logloss: 0.888319\tvalid_1's multi_logloss: 1.1197\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[21]\ttraining's multi_logloss: 0.880365\tvalid_1's multi_logloss: 1.11793\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[17]\ttraining's multi_logloss: 0.911063\tvalid_1's multi_logloss: 1.11698\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[30]\ttraining's multi_logloss: 0.82126\tvalid_1's multi_logloss: 1.12389\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[30]\ttraining's multi_logloss: 0.821004\tvalid_1's multi_logloss: 1.12108\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[29]\ttraining's multi_logloss: 0.827397\tvalid_1's multi_logloss: 1.12171\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[30]\ttraining's multi_logloss: 0.82126\tvalid_1's multi_logloss: 1.12389\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[30]\ttraining's multi_logloss: 0.821004\tvalid_1's multi_logloss: 1.12108\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[29]\ttraining's multi_logloss: 0.827397\tvalid_1's multi_logloss: 1.12171\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[30]\ttraining's multi_logloss: 0.82126\tvalid_1's multi_logloss: 1.12389\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[21]\ttraining's multi_logloss: 0.983418\tvalid_1's multi_logloss: 1.13178\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[30]\ttraining's multi_logloss: 0.821004\tvalid_1's multi_logloss: 1.12108\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[29]\ttraining's multi_logloss: 0.827397\tvalid_1's multi_logloss: 1.12171\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[24]\ttraining's multi_logloss: 0.971846\tvalid_1's multi_logloss: 1.13036\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[20]\ttraining's multi_logloss: 0.986976\tvalid_1's multi_logloss: 1.12921\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[21]\ttraining's multi_logloss: 0.983418\tvalid_1's multi_logloss: 1.13178\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[24]\ttraining's multi_logloss: 0.971846\tvalid_1's multi_logloss: 1.13036\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[20]\ttraining's multi_logloss: 0.986976\tvalid_1's multi_logloss: 1.12921\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[21]\ttraining's multi_logloss: 0.983418\tvalid_1's multi_logloss: 1.13178\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[24]\ttraining's multi_logloss: 0.971846\tvalid_1's multi_logloss: 1.13036\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[20]\ttraining's multi_logloss: 0.986976\tvalid_1's multi_logloss: 1.12921\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[29]\ttraining's multi_logloss: 0.954912\tvalid_1's multi_logloss: 1.13293\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[18]\ttraining's multi_logloss: 0.99437\tvalid_1's multi_logloss: 1.13248\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[19]\ttraining's multi_logloss: 0.990809\tvalid_1's multi_logloss: 1.13148\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[29]\ttraining's multi_logloss: 0.954912\tvalid_1's multi_logloss: 1.13293\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[18]\ttraining's multi_logloss: 0.99437\tvalid_1's multi_logloss: 1.13248\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[19]\ttraining's multi_logloss: 0.990809\tvalid_1's multi_logloss: 1.13148\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[29]\ttraining's multi_logloss: 0.954912\tvalid_1's multi_logloss: 1.13293\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[18]\ttraining's multi_logloss: 0.99437\tvalid_1's multi_logloss: 1.13248\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[19]\ttraining's multi_logloss: 0.990809\tvalid_1's multi_logloss: 1.13148\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[29]\ttraining's multi_logloss: 0.955668\tvalid_1's multi_logloss: 1.13194\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[30]\ttraining's multi_logloss: 0.951999\tvalid_1's multi_logloss: 1.13185\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[17]\ttraining's multi_logloss: 0.998904\tvalid_1's multi_logloss: 1.13155\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[29]\ttraining's multi_logloss: 0.955668\tvalid_1's multi_logloss: 1.13194\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[30]\ttraining's multi_logloss: 0.951999\tvalid_1's multi_logloss: 1.13185\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[17]\ttraining's multi_logloss: 0.998904\tvalid_1's multi_logloss: 1.13155\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[29]\ttraining's multi_logloss: 0.955668\tvalid_1's multi_logloss: 1.13194\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[30]\ttraining's multi_logloss: 0.951999\tvalid_1's multi_logloss: 1.13185\n",
      "Early stopping, best iteration is:\n",
      "[17]\ttraining's multi_logloss: 0.998904\tvalid_1's multi_logloss: 1.13155\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[23]\ttraining's multi_logloss: 0.965727\tvalid_1's multi_logloss: 1.12608\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[26]\ttraining's multi_logloss: 0.953374\tvalid_1's multi_logloss: 1.1247\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[23]\ttraining's multi_logloss: 0.965727\tvalid_1's multi_logloss: 1.12608\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[24]\ttraining's multi_logloss: 0.961451\tvalid_1's multi_logloss: 1.1231\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[26]\ttraining's multi_logloss: 0.953374\tvalid_1's multi_logloss: 1.1247\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[24]\ttraining's multi_logloss: 0.961451\tvalid_1's multi_logloss: 1.1231\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[23]\ttraining's multi_logloss: 0.965727\tvalid_1's multi_logloss: 1.12608\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[26]\ttraining's multi_logloss: 0.953374\tvalid_1's multi_logloss: 1.1247\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[24]\ttraining's multi_logloss: 0.961451\tvalid_1's multi_logloss: 1.1231\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[25]\ttraining's multi_logloss: 0.958433\tvalid_1's multi_logloss: 1.12901\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[24]\ttraining's multi_logloss: 0.962079\tvalid_1's multi_logloss: 1.12789\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[26]\ttraining's multi_logloss: 0.954286\tvalid_1's multi_logloss: 1.12708\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[25]\ttraining's multi_logloss: 0.958433\tvalid_1's multi_logloss: 1.12901\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[24]\ttraining's multi_logloss: 0.962079\tvalid_1's multi_logloss: 1.12789\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[26]\ttraining's multi_logloss: 0.954286\tvalid_1's multi_logloss: 1.12708\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[25]\ttraining's multi_logloss: 0.958433\tvalid_1's multi_logloss: 1.12901\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[24]\ttraining's multi_logloss: 0.962079\tvalid_1's multi_logloss: 1.12789\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[26]\ttraining's multi_logloss: 0.954286\tvalid_1's multi_logloss: 1.12708\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[47]\ttraining's multi_logloss: 0.88037\tvalid_1's multi_logloss: 1.12689\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[46]\ttraining's multi_logloss: 0.883087\tvalid_1's multi_logloss: 1.12726\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[42]\ttraining's multi_logloss: 0.896698\tvalid_1's multi_logloss: 1.12727\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[47]\ttraining's multi_logloss: 0.88037\tvalid_1's multi_logloss: 1.12689\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[46]\ttraining's multi_logloss: 0.883087\tvalid_1's multi_logloss: 1.12726\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[42]\ttraining's multi_logloss: 0.896698\tvalid_1's multi_logloss: 1.12727\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[47]\ttraining's multi_logloss: 0.88037\tvalid_1's multi_logloss: 1.12689\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[46]\ttraining's multi_logloss: 0.883087\tvalid_1's multi_logloss: 1.12726\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[42]\ttraining's multi_logloss: 0.896698\tvalid_1's multi_logloss: 1.12727\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[46]\ttraining's multi_logloss: 0.864415\tvalid_1's multi_logloss: 1.11939\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[38]\ttraining's multi_logloss: 0.894436\tvalid_1's multi_logloss: 1.11982\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[36]\ttraining's multi_logloss: 0.902265\tvalid_1's multi_logloss: 1.12061\n",
      "Training until validation scores don't improve for 30 rounds\n"
     ]
    }
   ],
   "source": [
    "# 初始化分類器\n",
    "classifier = TimeSeriesClassifier(window_size=10)\n",
    "target_n=4\n",
    "# 使用多執行緒進行參數調優\n",
    "train_end_idx = int(len(df_train) * 0.8)\n",
    "results_df = classifier.tune_parameters(\n",
    "    df_train,\n",
    "    features,\n",
    "    targets[target_n],\n",
    "    val_start_idx=train_end_idx,\n",
    "    n_jobs=4,  # 使用4個執行緒，設為-1表示使用所有可用CPU\n",
    ")\n",
    "\n",
    "# 使用最佳參數訓練模型\n",
    "classifier.train(df_train, features, targets[target_n], val_start_idx=train_end_idx)\n",
    "\n",
    "# 驗證模型\n",
    "validation_results = classifier.validate(\n",
    "    df_validation, targets[target_n : target_n + 1]\n",
    ")\n",
    "\n",
    "# 預測（如果需要）\n",
    "# predictions = classifier.predict(df_predict, targets)\n",
    "\n",
    "# 查看參數調優結果\n",
    "print(\"\\nParameter tuning results:\")\n",
    "print(results_df.sort_values(\"score\", ascending=False).head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
